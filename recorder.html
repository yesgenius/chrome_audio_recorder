<!--
  recorder.html

  A professional example of capturing raw PCM audio (16-bit, mono, 16 kHz) via getUserMedia in Chrome on Android 14,
  and saving it as an uncompressed WAV file. The code attempts to minimize or disable all audio transformations.

  IMPORTANT NOTES:
  1) Browsers often do not strictly honor the exact sample rate or channel count requested in constraints.
  2) The ScriptProcessorNode is deprecated, but it is used here for simplicity to illustrate raw audio capture.
     A more modern approach would involve AudioWorklet.
  3) Some internal transformations may still occur due to browser or device limitations. This example requests
     specific constraints (16 kHz, 1 channel, 16-bit, no echo cancellation, etc.) and then captures whatever
     raw stream is provided.
  4) This example logs the final stream parameters so you can see what the browser actually provided.
-->

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <title>Audio Recorder (PCM/WAV)</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
    }
    #consoleOutput {
      white-space: pre-wrap; 
      background: #f0f0f0; 
      padding: 10px; 
      border: 1px solid #ccc;
      margin-top: 10px;
      width: 100%;
      max-height: 250px;
      overflow-y: auto;
    }
    button {
      padding: 10px 20px;
      margin-right: 10px;
      font-size: 16px;
    }
    #status {
      font-weight: bold;
    }
  </style>
</head>
<body>

<h2>PCM/WAV Audio Recorder</h2>

<!-- Output file name display -->
<div>
  <label><strong>Output Filename:</strong></label>
  <span id="outputFileName"></span>
</div>

<!-- Display the requested constraints and final settings -->
<div>
  <label><strong>Requested Constraints:</strong></label>
  <pre id="requestedConstraints"></pre>
</div>
<div>
  <label><strong>Browser Actual Audio Track Settings:</strong></label>
  <pre id="actualTrackSettings"></pre>
</div>

<!-- Status display -->
<div id="status">Status: Not recording</div>

<!-- Record/Stop button -->
<button id="recordBtn">Record</button>

<!-- Console-like area to show logs, errors, or debug info -->
<div id="consoleOutput"></div>

<script>
/**
 * Log messages to the #consoleOutput div for clarity.
 * @param {String} message - The text to append to the console output.
 */
function logMessage(message) {
  const consoleDiv = document.getElementById('consoleOutput');
  consoleDiv.textContent += message + "\n";
  consoleDiv.scrollTop = consoleDiv.scrollHeight; // auto-scroll
}

/**
 * Creates a standard WAV file header for PCM audio and appends raw PCM samples to it.
 * @param {Int16Array} samples - The raw 16-bit PCM samples.
 * @param {Number} sampleRate - The sampling rate (e.g., 16000).
 * @param {Number} numChannels - The number of channels (e.g., 1 for mono).
 * @returns {Blob} - The resulting Blob containing the WAV file data.
 */
function encodeWAV(samples, sampleRate, numChannels) {
  // Calculate buffer sizes
  const bytesPerSample = 2; // 16-bit
  const blockAlign = numChannels * bytesPerSample;
  const byteRate = sampleRate * blockAlign;
  const dataLength = samples.length * bytesPerSample;
  const buffer = new ArrayBuffer(44 + dataLength);
  const view = new DataView(buffer);

  let offset = 0;

  // RIFF chunk descriptor
  writeString(view, offset, 'RIFF'); offset += 4;
  view.setUint32(offset, 36 + dataLength, true); offset += 4;  // file size - 8
  writeString(view, offset, 'WAVE'); offset += 4;

  // FMT sub-chunk
  writeString(view, offset, 'fmt '); offset += 4;
  view.setUint32(offset, 16, true); offset += 4;               // Size of the 'fmt ' chunk
  view.setUint16(offset, 1, true); offset += 2;                // PCM (uncompressed)
  view.setUint16(offset, numChannels, true); offset += 2;      // Number of channels
  view.setUint32(offset, sampleRate, true); offset += 4;       // Sample rate
  view.setUint32(offset, byteRate, true); offset += 4;         // Byte rate
  view.setUint16(offset, blockAlign, true); offset += 2;       // Block align
  view.setUint16(offset, 16, true); offset += 2;               // Bits per sample

  // data sub-chunk
  writeString(view, offset, 'data'); offset += 4;
  view.setUint32(offset, dataLength, true); offset += 4;

  // Write the PCM samples
  let i = 0;
  while (i < samples.length) {
    view.setInt16(offset, samples[i], true);
    offset += 2;
    i++;
  }

  return new Blob([view], { type: 'audio/wav' });
}

/**
 * Helper function to write ASCII strings to DataView.
 */
function writeString(view, offset, string) {
  for (let i = 0; i < string.length; i++) {
    view.setUint8(offset + i, string.charCodeAt(i));
  }
}

/**
 * Generates a timestamp-based filename in the form YYYY-MM-DD_HHMMSS.WAV
 * @returns {String} - The generated filename.
 */
function generateFileName() {
  const now = new Date();
  const year = now.getFullYear();
  const month = String(now.getMonth() + 1).padStart(2, '0');
  const day = String(now.getDate()).padStart(2, '0');
  const hours = String(now.getHours()).padStart(2, '0');
  const minutes = String(now.getMinutes()).padStart(2, '0');
  const seconds = String(now.getSeconds()).padStart(2, '0');
  return `${year}-${month}-${day}_${hours}${minutes}${seconds}.WAV`;
}

// Audio constraints for raw PCM capture (16-bit, mono, 16kHz).
// We disable all enhancements (echoCancellation, noiseSuppression, etc.)
const constraints = {
  audio: {
    channelCount: 1,
    sampleRate: 16000,
    sampleSize: 16,
    echoCancellation: false,
    noiseSuppression: false,
    autoGainControl: false,
    // Non-standard constraints recognized by Chrome:
    googEchoCancellation: false,
    googAutoGainControl: false,
    googNoiseSuppression: false,
    googHighpassFilter: false,
    googTypingNoiseDetection: false
  },
  video: false
};

// Elements
const recordBtn = document.getElementById('recordBtn');
const statusEl = document.getElementById('status');
const outputFileNameEl = document.getElementById('outputFileName');
const requestedConstraintsEl = document.getElementById('requestedConstraints');
const actualTrackSettingsEl = document.getElementById('actualTrackSettings');

// Global state
let mediaStream = null;
let audioContext = null;
let scriptProcessor = null;
let isRecording = false;
let leftChannelData = []; // We only record mono, so we'll store data in a single array
let recordingLength = 0;
let fileName = '';

// Show the user what constraints were requested
requestedConstraintsEl.textContent = JSON.stringify(constraints, null, 2);

recordBtn.addEventListener('click', async () => {
  if (!isRecording) {
    // ----- Start Recording -----
    await startRecording();
  } else {
    // ----- Stop Recording -----
    await stopRecording();
  }
});

/**
 * Start the recording process:
 * 1. Check if browser supports getUserMedia.
 * 2. Request audio stream with constraints.
 * 3. Set up AudioContext, ScriptProcessor to capture raw PCM frames.
 * 4. Update UI status and button label.
 */
async function startRecording() {
  // Check for getUserMedia support
  if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    logMessage("getUserMedia is not supported in this browser.");
    statusEl.textContent = "Status: Unable to record (no getUserMedia).";
    return;
  }

  try {
    // Request audio stream
    mediaStream = await navigator.mediaDevices.getUserMedia(constraints);

    // Show the actual track settings
    // Note: Some browsers do not fully populate these fields, but Chrome typically does.
    const audioTracks = mediaStream.getAudioTracks();
    if (audioTracks.length > 0) {
      actualTrackSettingsEl.textContent = JSON.stringify(audioTracks[0].getSettings(), null, 2);
    }

    // Create file name
    fileName = generateFileName();
    outputFileNameEl.textContent = fileName;

    // Clear any old data
    leftChannelData = [];
    recordingLength = 0;
    logMessage("Recording started. Raw audio data will be collected.");

    // Create AudioContext. Attempt to enforce 16 kHz if possible.
    // Some browsers might ignore this.
    audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });

    // Create a source from our MediaStream
    const source = audioContext.createMediaStreamSource(mediaStream);

    // The bufferSize can be 1024, 2048, 4096, 8192, or 16384.
    // Larger sizes are safer to avoid glitches. We'll pick 4096 here.
    const bufferSize = 4096;
    const numberOfInputChannels = 1;
    const numberOfOutputChannels = 1;

    // Create the ScriptProcessorNode for capturing raw PCM data
    scriptProcessor = audioContext.createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels);

    // Event fired whenever the buffer is full
    scriptProcessor.onaudioprocess = (audioProcessingEvent) => {
      // Input buffer is where the microphone data is captured
      const inputBuffer = audioProcessingEvent.inputBuffer;
      // We only record channel 0 (mono)
      const inputData = inputBuffer.getChannelData(0);
      // Convert float samples to 16-bit PCM
      const pcmData = new Int16Array(inputData.length);
      for (let i = 0; i < inputData.length; i++) {
        // scale from float -1..1 to int16
        pcmData[i] = Math.max(-1, Math.min(1, inputData[i])) * 0x7FFF;
      }
      leftChannelData.push(pcmData);
      recordingLength += pcmData.length;
    };

    // Connect the graph
    source.connect(scriptProcessor);
    scriptProcessor.connect(audioContext.destination);

    // Update UI
    isRecording = true;
    recordBtn.textContent = "Stop";
    statusEl.textContent = "Status: Recording...";

    // Log real audio parameters accepted by the AudioContext
    logMessage(`AudioContext sampleRate: ${audioContext.sampleRate}`);
  } catch (err) {
    // Log the error if user refused or something else went wrong
    logMessage("Error accessing microphone: " + err.message);
    statusEl.textContent = "Status: Unable to record (microphone access error).";
  }
}

/**
 * Stop the recording process:
 * 1. Disconnect media stream, script processor, audio context.
 * 2. Concatenate raw PCM data and encode into a WAV file.
 * 3. Offer download of the WAV file.
 * 4. Update UI status and button label.
 */
async function stopRecording() {
  isRecording = false;
  statusEl.textContent = "Status: Stopped recording.";
  recordBtn.textContent = "Record";

  // Stop capturing from the scriptProcessor
  if (scriptProcessor) {
    scriptProcessor.disconnect();
    scriptProcessor.onaudioprocess = null;
    scriptProcessor = null;
  }

  // Stop the AudioContext
  if (audioContext) {
    // Attempt to close the context
    await audioContext.close().catch(err => logMessage("Error closing audioContext: " + err));
    audioContext = null;
  }

  // Stop all tracks
  if (mediaStream) {
    mediaStream.getTracks().forEach(track => track.stop());
    mediaStream = null;
  }

  // Combine all chunks of recorded data into a single Int16Array
  const mergedBuffers = mergeBuffers(leftChannelData, recordingLength);
  // The sample rate is from the AudioContext or the input track
  const finalSampleRate = 16000; // or audioContext?.sampleRate if you want to reflect actual
  // Encode the data as a WAV blob
  const wavBlob = encodeWAV(mergedBuffers, finalSampleRate, 1);

  // Provide a link to download the WAV file
  const url = URL.createObjectURL(wavBlob);
  const link = document.createElement('a');
  link.href = url;
  link.download = fileName;
  link.style.display = 'block';
  link.textContent = "Download " + fileName;
  document.body.appendChild(link);

  logMessage("Recording saved as WAV. File ready for download.");
}

/**
 * Merges an array of Int16Array into a single Int16Array.
 * @param {Int16Array[]} channelBuffers - Array of Int16Array buffers to merge.
 * @param {Number} totalLength - The total number of samples across all buffers.
 * @returns {Int16Array} The merged Int16Array containing all samples.
 */
function mergeBuffers(channelBuffers, totalLength) {
  const result = new Int16Array(totalLength);
  let offset = 0;
  for (let i = 0; i < channelBuffers.length; i++) {
    result.set(channelBuffers[i], offset);
    offset += channelBuffers[i].length;
  }
  return result;
}
</script>

</body>
</html>
